<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.299">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Text mining with R</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="text_mining_with_R_files/libs/clipboard/clipboard.min.js"></script>
<script src="text_mining_with_R_files/libs/quarto-html/quarto.js"></script>
<script src="text_mining_with_R_files/libs/quarto-html/popper.min.js"></script>
<script src="text_mining_with_R_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="text_mining_with_R_files/libs/quarto-html/anchor.min.js"></script>
<link href="text_mining_with_R_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="text_mining_with_R_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="text_mining_with_R_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="text_mining_with_R_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="text_mining_with_R_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Text mining with R</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="cell">
<style type="text/css">
.box
{
    border: 1px solid;
  border-radius: 5px;
    padding: 10px;
    margin: 10px 10px 10px 10px;
}

.sub-box
{
  display: flex; 
  flex-direction: row; 
  align-items: center;
}

.type1
{
    border-color: #E76F51;
    background-color: rgba(231, 111, 81, 0.1); 
}

.type2
{
    border-color: #2A9D8F;
    background-color: rgba(42, 157, 143, 0.1); 
}

.type3
{
    border-color: #0096C7;
    background-color: rgba(0, 150, 199, 0.1); 
}

.type4
{
    border-color: #00B353;
    background-color: rgba(0, 179, 83, 0.1); 
}

.type5
{
    border-color: #836953;
    background-color: #E5D3B3; 
}

.picture
{
    width: 30px; 
    height: 30px;
    margin: 0 0 10px 0;
}
</style>
</div>
<section id="preliminaries" class="level3">
<h3 class="anchored" data-anchor-id="preliminaries">Preliminaries</h3>
<p>Few lines and scheme of tidyverse pipeline</p>
</section>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<p>In this session we will see how to perform basic <strong>text mining</strong> with R. Text mining refers to the process of extracting (<em>mining</em>) information and insights from text. As text is written with human language, it is by nature subjective and ambigous. However, text mining can be extremely useful when looking for any sort of pattern, trend, or relantionships in large volumes of text data (articles, documents, emails, social media posts, etc).</p>
<p>Text mining, or text analysis, can be a very challenging task as text data is often <em>unstructured</em>, i.e.&nbsp;it does not have a predefined format or structure. Furthermore, as we said, text is written in natural language and contains all the ambiguity of human subjects. In addition to these aspects, considering that everything ever written is text, the volume of data available for mining is huge and very “noisy”, i.e.&nbsp;it contains a lot of irrelevant information, typos, etc. For these and several other reasons, text mining requires quite sophisticated techniques to obtain meaningful results.</p>
<p>Thankfully, most of these techniques have already been implemented into <em>packages</em> ( ready-to-use pieces of code) in different programming languanges (including R). In particular, the package <code>tidytext</code> is designed to work with text data in a “tidy” and efficient manner. The package is built on top of the tidyverse suite of packages (you can read more about <code>todytext</code> <a url="https://github.com/juliasilge/tidytext" href="">here</a>). <code>tidytext</code> provides a set of tools (functions) for manipulating and analyzing text data, these tools allow users to easily convert unstructured text data into a structured format that can be analyzed using statistics. In this session we will go through the basic steps of the general text mining process using <code>tidytext</code>, in particular we will use its functions to perform data collection, preprocessing, feature extraction, text classification, and visualization.</p>
<p>The paragraphs of this session are organised in descriptive text, code with its output (DataFrames, computations, plots, etc), and code description. The descriptive text is simply plain text as the one you are reading right now. Code will be into grey boxes and its output will immidiatly follows those like in this example:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="st">'Good luck guys!'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Good luck guys!"</code></pre>
</div>
</div>
<p>When necessary, code and outputs blocks are followed by a line-by-line explanation of the operations executed in the code box:</p>
<div class="box type5">
<div class="sub-box">
<img src="pictures/icons/code_expl.png" alt="Icon" class="picture">
<p style="margin-left: 10px;">
</p><h5 class="anchored">
<strong>How does it work?</strong>
</h5>
<p></p>
</div>
<p>
</p><ul>
<li>
The function <code>print()</code> displayed the custom message “Good luck guys!” as an encouragement to all the students following the course.
</li>
</ul>
<p></p>
</div>
</section>
<section id="reading-data" class="level3">
<h3 class="anchored" data-anchor-id="reading-data">Reading data</h3>
<p>In this session we will work with data that we already collected using the web application <a url="https://ianalyzer.hum.uu.nl/home" href="">I-Analyzer</a>. We obtained our data querying for “european union” over the news of the Times Digital Archive between 1945 and 2012. The data are stored in a coma-separated-values (csv) file and we are going to convert them into an R dataframe:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
✔ ggplot2 3.4.0     ✔ purrr   1.0.1
✔ tibble  3.1.8     ✔ dplyr   1.1.0
✔ tidyr   1.3.0     ✔ stringr 1.5.0
✔ readr   2.1.3     ✔ forcats 1.0.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>data_file_name <span class="ot">&lt;-</span> <span class="st">'../data/times_ocr=80_100&amp;date=1945-01-01_2010-12-31&amp;query=_european_union_&amp;category=News.csv'</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>data_df <span class="ot">&lt;-</span> <span class="fu">read_delim</span>(data_file_name, <span class="at">delim =</span> <span class="st">";"</span>, <span class="at">escape_double =</span> <span class="cn">FALSE</span>, <span class="at">col_types =</span> <span class="fu">cols</span>(<span class="st">`</span><span class="at">date-pub</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">col_date</span>(<span class="at">format =</span> <span class="st">"%B %d, %Y"</span>)), <span class="at">trim_ws =</span> <span class="cn">TRUE</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">nrow</span>(data_df))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1532</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">colnames</span>(data_df))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "author"   "category" "content"  "date-pub" "edition"  "issue"    "query"   
[8] "title"    "volume"  </code></pre>
</div>
</div>
<div class="box type5">
<div class="sub-box">
<img src="pictures/icons/code_expl.png" alt="Icon" class="picture">
<p style="margin-left: 10px;">
</p><h5 class="anchored">
<strong>How does it work?</strong>
</h5>
<p></p>
</div>
<p>
</p><ul>
<li>
We first load the library <code>readr</code> as it contains all sort of dunctions to read files into R DataFrames. We also load the library <code>tidyverse</code> as it contains a lot of useful functions for data manipulation and visualization. Furthermore it will allow us to use the tidyverse pipeline syntax;
</li>
<li>
We store the name of our dataset into the variable <code>data_file_name</code>. The name includes the <em>realtive</em> path of the data, as the code is supposed to be ran in the <em>book</em> folder of the provided material;
</li>
<li>
We read the data using <code>read_delim()</code>, a function to read coma separated files (csv) and more into R DataFrames. In this case, we obtained all the necessary arguments clicking on “Import Dataset” in the Environment window (top-right) of R studio. In particular, we gave instructions to convert the date of publication column (“date-pub”) data format (&lt;month_str&gt; &lt;day&gt;, &lt;year&gt;) into an R date object;
</li>
<li>
We finally printed the names of the columns in our DataFrame using <code>colnames()</code>.
</li>
</ul>
<p></p>
</div>
<p>We now have all the data we need in a single R DataFrame, <code>data_df</code>, the starting point of our analysis. The information we are most interested in it’s stored in the “content” column. Let’s see how to extract this information.</p>
</section>
<section id="preprocessing" class="level3">
<h3 class="anchored" data-anchor-id="preprocessing">Preprocessing</h3>
<section id="tokenization" class="level4">
<h4 class="anchored" data-anchor-id="tokenization">Tokenization</h4>
<p>As we mentioned in the introduction, text data in unstructured and it is up to us to define a data structure suitable for the kind of text analysis we want to perform. We want our data structure to be comprehensive and such that can be easily manipulated according to our needs. Having this goal in mind, a possibility is to divide text into either characters, words, or paragraphs and to obtain a data set where each row contains one of these elements and all its relative information.</p>
<p>The process of dividing a string of text into meaningful units is called <strong>Tokenization</strong> and these meaningful units are called <strong>tokens</strong>. A token can be a word, a phrase, a paragraphs, or a single character depending on the nature of our analysis. If, for example, we want just to explore how many times the name of a certain politician is mentioned in a speach, our tokens would probably be all the words of the speech and our analysis would consist on counting how many tokens are equal to the name of the politician.</p>
<p>To perform “good” text mining, not only we want to optimally “tokenize” our text, but also organize our tokens in a <em>tidy</em> way, quite literally! For the R community, “tidy” has a very specific meaning, i.e.&nbsp;structuring data sets to make them consistent, easy to work, and easy to analyse. In our context it means having a single token per data frame row. R allows us to perform all these operations in few lines thanks to the library <code>tidytext</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidytext)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>tidy_content <span class="ot">&lt;-</span> data_df <span class="sc">%&gt;%</span> <span class="fu">unnest_tokens</span>(word, content, <span class="at">token=</span><span class="st">"words"</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>tidy_content</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1,549,578 × 9
   author              categ…¹ `date-pub` edition issue query title volume word 
   &lt;chr&gt;               &lt;chr&gt;   &lt;date&gt;     &lt;lgl&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt;  &lt;chr&gt;
 1 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     from 
 2 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     a    
 3 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     spec…
 4 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     corr…
 5 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     at   
 6 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     this 
 7 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     junc…
 8 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     of   
 9 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     focus
10 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     on   
# … with 1,549,568 more rows, and abbreviated variable name ¹​category</code></pre>
</div>
</div>
<div class="box type5">
<div class="sub-box">
<img src="pictures/icons/code_expl.png" alt="Icon" class="picture">
<p style="margin-left: 10px;">
</p><h5 class="anchored">
<strong>How does it work?</strong>
</h5>
<p></p>
</div>
<p>
</p><ul>
<li>
We first load the library <code>tidytext</code> containing all the functions we need for text mining;
</li>
<li>
We use the <code>tidytext</code> function <code>unnest_tokens()</code> to split the text stored in the column <em>content</em> of our DataFrame <code>data_df</code> into words. First of all, we “feed” our raw data DataFrame to the function using the workflow syntax <code>data_df %&gt;%       unnest_tokens(...)</code>. This is equivalent to specify the DataFrame as the first argument of the function, i.e.&nbsp;<code>unnest_tokens(data_df, work,content,token="words")</code>. The other three arguments of the function specify the name of the column containing the tokens (<em>word</em>), the text that needs to be tokenized (the column <em>content</em>), and the kind of token (in our case, words).
</li>
</ul>
<p></p>
</div>
<p>In the code block above we use the function <code>unnest_tokens()</code> to tokenize the content of our DataFrame. A quick view of the resulting DataFrame <code>tidy_content</code> shows us that the <em>content</em> column is gone, while a column named <em>word</em> now appears at the end of the DataFrame. How do we know which word belongs to which content AFTER tokenization? Is that information lost? The content in your raw data DataFrame has a unique identifier associated with it, in our case the identifier is stored in the column <em>issue</em>. As the column <em>issue</em> is <em>still</em> present in <code>tidy_content</code>, each word, or token, has therefore a unique identifier specifying from which content it came from.</p>
</section>
<section id="cleaning-data" class="level4">
<h4 class="anchored" data-anchor-id="cleaning-data">Cleaning data</h4>
<p>Cleaning data is an essential step in any data analysis process. Before you can analyse a dataset, you need to ensure that the data is accurate (data values are correct and free from errors), complete, and consistent (uniform and following a standard format or structure). Data cleaning is the process of identifying and correcting or removing errors, inconsistencies, and inaccuracies from a dataset. The output of I-Analyzer data (the csv file we are using for our analysis) is already a consistent data set, however, every time one of our programs performs some sort of operation on the data set, errors may be introduced. The absolute nightmare of every data scientist are missing or undefined values, these usually appear in our data sets as “NA” (Not Available) or “NaN” (Not a Number). NA is used in R (and some other programming languages) to represent missing or undefined values in data. You will find NaN more often in Python or Javascript programming. In general NA is used for non-numeric data types like characters and NaN for numeric data types, but the most important thing to remember is that you want to find our if your data set contains any of these values as they may severely affect your data analysis results. Does our DataFrame contain any NA values in the issue column? Let’s find out!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>are_there_na <span class="ot">&lt;-</span> <span class="fu">any</span>(<span class="fu">is.na</span>(tidy_content<span class="sc">$</span>issue))</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (are_there_na) {</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="st">'WARNING! There are NA in your data!'</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="st">'Lucky you! I could not find any NA in your data (yet...)!'</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "WARNING! There are NA in your data!"</code></pre>
</div>
</div>
<div class="box type5">
<div class="sub-box">
<img src="pictures/icons/code_expl.png" alt="Icon" class="picture">
<p style="margin-left: 10px;">
</p><h5 class="anchored">
<strong>How does it work?</strong>
</h5>
<p></p>
</div>
<p>
</p><ul>
<li>
The function <code>is.na(data_df)</code> scans all the values of our DataFrame and returns another DataFrame made of boolean variables, i.e.&nbsp;True or False depending if the scanned value is a NA or not, respectively. We then apply the function <code>any()</code> to this boolean DataFrame to check if there is AT LEAST one TRUE value and, therefore, one NA value. If so, <code>any()</code> will return TRUE, FALSE otherwise. This result is stored in the variable <em>are_there_na</em> that, indeed, will be TRUE or FALSE depending if there is at least one NA in our data set or nor;
</li>
<li>
We use a conditional statement IF … ELSE … to print two messages depending on the value of the variable are_there_na.
</li>
</ul>
<p></p>
</div>
<p>We found NA in our DataSet. Nothing to worry about, this is the common case, so common that there are plenty of functions to clean up our data. How shall we procede in this case? usually we would like to inspect the data to check what is missing and how to better replace those values. In our case, you can relatively easily find out that one of the issues identifier is missing. For simplicity, we will just exclude the issue from our data set using the function <code>na.omit()</code> that, indeed, removes all the rows containing NA returning a “clean” DataFrame:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>tidy_content <span class="ot">&lt;-</span> tidy_content[<span class="sc">!</span><span class="fu">is.na</span>(tidy_content<span class="sc">$</span>issue), ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s check if there are still NA in our data set:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>are_there_na <span class="ot">&lt;-</span> <span class="fu">any</span>(<span class="fu">is.na</span>(tidy_content<span class="sc">$</span>issue))</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (are_there_na) {</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="st">'WARNING! There are NA in your data!'</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="st">'Lucky you! I could not find any NA in your data (yet...)!'</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Lucky you! I could not find any NA in your data (yet...)!"</code></pre>
</div>
</div>
<hr>
<p>As we mentioned before, text is unstructured data that can be very “noisy”, i.e.&nbsp;containing a lot of not relevant information. Actually, the most common words in a text are words that have very little meaning, such as “the”, “and”, “a”, etc. These words are referred as <em>stop words</em> and cleaning data from text mining includes removing stop words from our tokenised data:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(stop_words)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>tidy_clean_content <span class="ot">&lt;-</span> tidy_content <span class="sc">%&gt;%</span> <span class="fu">anti_join</span>(stop_words)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>tidy_clean_content</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 801,754 × 9
   author              categ…¹ `date-pub` edition issue query title volume word 
   &lt;chr&gt;               &lt;chr&gt;   &lt;date&gt;     &lt;lgl&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt;  &lt;chr&gt;
 1 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     spec…
 2 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     corr…
 3 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     junc…
 4 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     focus
 5 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     euro…
 6 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     37   
 7 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     women
 8 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     sat  
 9 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     round
10 ['FROM A SPECIAL C… ['News… 1962-11-05 NA      55540 time… Euro… NA     conf…
# … with 801,744 more rows, and abbreviated variable name ¹​category</code></pre>
</div>
</div>
<div class="box type5">
<div class="sub-box">
<img src="pictures/icons/code_expl.png" alt="Icon" class="picture">
<p style="margin-left: 10px;">
</p><h5 class="anchored">
<strong>How does it work?</strong>
</h5>
<p></p>
</div>
<p>
</p><ul>
<li>
<code>data(stop_words)</code> loads a data set containing the most commonly used stop words in English language into the R environment. If you are in R studio you will now see in your Environment tab (the top-right one) a new DataFrame called <em>stop_words</em>;
</li>
<li>
Using the function <code>anti_join()</code> we select those rows (so words) in the DataFrame <em>tidy_content</em> that do <strong>NOT</strong> match the stop words. In other words, we created a new DataFrame (<em>tidy_clean_content</em>) removing all the stop words listed in <em>stop_words</em> from <em>tidy_content</em>.
</li>
</ul>
<p></p>
</div>
<p>With the few lines of code above, we cleaned up the <code>tidy_content</code> DataFrame from stop words. We perfomed basic data cleaning and our data set is now ready for some analysis.</p>
</section>
</section>
<section id="text-analysis" class="level3">
<h3 class="anchored" data-anchor-id="text-analysis">Text Analysis</h3>
<section id="counting-words" class="level4">
<h4 class="anchored" data-anchor-id="counting-words">Counting words</h4>
<p>After having tokenised and cleaned our data, it’s time to perform the most basic text mining operation: count the number of times a certain word appears in our text. Even if conceptually it seems a quite trivial operation, by counting the frequency of each word in a text we can gain important insights about the general characteristics of the text. Furthermore, counting the frequency of specific words (i.e.&nbsp;how many times they occur per sentence/text/paragraph/document/etc) we can classify a text or define a model to identify the underlying topic or theme.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>word_count <span class="ot">&lt;-</span> tidy_clean_content <span class="sc">%&gt;%</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(word) <span class="sc">%&gt;%</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(n <span class="sc">&gt;</span> <span class="dv">2000</span>) <span class="sc">%&gt;%</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">word =</span> <span class="fu">reorder</span>(word, n)) </span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>word_count <span class="sc">%&gt;%</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(n, word)) <span class="sc">+</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="cn">NULL</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="text_mining_with_R_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="box type5">
<div class="sub-box">
<img src="pictures/icons/code_expl.png" alt="Icon" class="picture">
<p style="margin-left: 10px;">
</p><h5 class="anchored">
<strong>How does it work?</strong>
</h5>
<p></p>
</div>
<p>
</p><ul>
<li>
We “inject” our data as input of the function <code>count()</code> that, indeed, counts the identical entries of the column <em>word</em>. <code>count()</code> has an argument (<em>name</em>) that it is used to specify the name of the column where the count values will be stored. In this case, the <em>name</em> argument is omitted, therefore, by default the name of the column will be <em>n</em>. After using <code>count()</code>, the result is a DataFrame with two columns: the quantity that has been counted (<em>word</em>) and the result of the counting (<em>n</em>).<br> There are a lot of words in our text and it would be not very convenient plotting all of them, so we apply the function <code>filter()</code> to select only those words with count (column <em>n</em>) larger than 2000. We also want words to be displayed in descending order of counts, to do that we use the function <code>mutate()</code> to substitute the column <em>word</em> with the same column (<em>word</em>) arranged by counts (<em>n</em>). To rearrange the words in order of counts we use the function <code>reorder()</code>. We store the result in the DataFrame <em>word_count</em>;
</li>
<li>
Time to plot! We “feed” our data to the function <code>ggplot()</code>, in it we specify x and y axis to plot with <code>aes(n, word)</code> (<code>aes</code> stand for aesthetic). <code>geom_col()</code> specified that type of plot, in this case a column chard or a bar chart, and <code>labs(y = NULL)</code> removes the y-axis label (as it is quite obvious that we are visualising words).
</li>
</ul>
<p></p>
</div>
<p>Looking at the data, we are not surprised to see that the second most frequent word is “european” as we are analysing data extracted from querying “European Union”. It is interesting to note that the third word is “vote”. This may mean that all the times “European Union” was mentioned in the news, it wa,s most of the times, related to the topic of elections.</p>
<p>A very popular way to visualise the most common words in a sample of texts is a <strong>word cloud</strong>. A word cloud is a graphical representation of words where the size of each word indicates its frequency within a given data set. Visualising our data using a word cloud is not particularly useful for quantitative analysis, but it can be very effective when communicating text mining results. Obtaining a word cloud plot in R is as easy as all the tasks we performed so far, we just need to download the package <code>workcloud</code> and use the function <code>wordcloud()</code> as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(wordcloud)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: RColorBrewer</code></pre>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>word_count <span class="sc">%&gt;%</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">with</span>(<span class="fu">wordcloud</span>(word, n, <span class="at">max.words =</span> <span class="dv">1000</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="text_mining_with_R_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="word-classification-and-sentiment-analysis" class="level4">
<h4 class="anchored" data-anchor-id="word-classification-and-sentiment-analysis">Word classification and Sentiment Analysis</h4>
<p>Can we run a text analysis to evaluate if a sentence is sad or if the general mood of a story is positive or negative? We actually can and this may seem surprising as the mood or the <em>sentiment</em> related to a text seems something very subjective and highly affected by human personal judgement and background. According to wikipedia, <strong>sentiment analysis</strong> (also known as <strong>opinion mining</strong> or <strong>emotion AI</strong>) is the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information. Sentiment analysis can be very complex, so complex that should deserve a dedicated course. In this session we will perform a very basic sentiment analysis so that you can grasp its main principles and workflow.</p>
<p>Sentiment analysis is based on the assumption that we can view a text as a combination of individual words and that, having assigned a sentiment to each individual word, the resulting sentiment of the text will be the sum of the sentiment of its individual words. For example, if most of the words in a text are positive, then the text can be classified as positive. Given this assumption, to perform sentiment analysis, we need a reference database of words where a sentiment has been assigned to each word following specific conventions. Such a database is called <strong>lexicon</strong>. For our practical purposes a lexicon is just a DataFrame where a score is assigned to words or phrases, the score indicating whether the corresponding word is associated with positive or negative sentiment. For example, the word “happy” will probably have a positive score, while the word “sad” may have a negative score.</p>
<p>For our simple analysis, we already downloaded a lexicon, the <strong>NRC emotion lexicon</strong>. The NRC Emotion Lexicon is a list of English words and their associations with eight basic emotions (anger, fear, anticipation, trust, surprise, sadness, joy, and disgust) and two sentiments (negative and positive). If an emotion is associated with a word, its score will be 1, 0 otherwise.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>nrc_lexicon_df <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">"../data/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt"</span>, <span class="at">header =</span> <span class="cn">FALSE</span>, <span class="at">sep =</span> <span class="st">"</span><span class="sc">\t</span><span class="st">"</span>, <span class="at">stringsAsFactors =</span> <span class="cn">FALSE</span>, <span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">"word"</span>, <span class="st">"emotion"</span>, <span class="st">"score"</span>))</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>joy_words <span class="ot">&lt;-</span> nrc_lexicon_df  <span class="sc">%&gt;%</span> </span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(emotion <span class="sc">==</span> <span class="st">"joy"</span> <span class="sc">&amp;</span> score <span class="sc">==</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="box type5">
<div class="sub-box">
<img src="pictures/icons/code_expl.png" alt="Icon" class="picture">
<p style="margin-left: 10px;">
</p><h5 class="anchored">
<strong>How does it work?</strong>
</h5>
<p></p>
</div>
<p>
</p><ul>
<li>
The NRC emotion lexicon is located in the data folder and it is stored in a .txt file (even if technically it is a tab separated values file). To read its content into an R DataFrame we use the same procedure we used for our raw data;
</li>
<li>
Once we have stored the lexicon into the DataFrame <em>nrc_lexicon_df</em> we can filter only the “happy” words applying the function <code>filter()</code> and specifying that only words with emotion <em>joy</em> and score 1 are going to be considered. The result is stored into the DataFrame <em>joy_words</em>.
</li>
</ul>
<p></p>
</div>
<p>In the previous lines we read the lexicon into an R DataFrame and we extracted from it only the words associated with joy. Once we know which are the words associated with joy, we can count how many “joy words” there are in our text and see if the news associated with “European Union” can be classified as “joyful” or not.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>issue_df <span class="ot">&lt;-</span> tidy_clean_content <span class="sc">%&gt;%</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="st">`</span><span class="at">date-pub</span><span class="st">`</span><span class="sc">&gt;=</span><span class="st">'2000-01-01'</span> <span class="sc">&amp;</span> <span class="st">`</span><span class="at">date-pub</span><span class="st">`</span> <span class="sc">&lt;</span> <span class="st">'2010-01-01'</span>) <span class="sc">%&gt;%</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(issue) <span class="sc">%&gt;%</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">reframe</span>(<span class="at">words_per_issue =</span> <span class="fu">n</span>(), <span class="at">date=</span> <span class="st">`</span><span class="at">date-pub</span><span class="st">`</span>) <span class="sc">%&gt;%</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unique</span>()</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>issue_joy_df <span class="ot">&lt;-</span> tidy_clean_content <span class="sc">%&gt;%</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="st">`</span><span class="at">date-pub</span><span class="st">`</span><span class="sc">&gt;=</span><span class="st">'2000-01-01'</span> <span class="sc">&amp;</span> <span class="st">`</span><span class="at">date-pub</span><span class="st">`</span> <span class="sc">&lt;</span> <span class="st">'2010-01-01'</span>) <span class="sc">%&gt;%</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">inner_join</span>(joy_words) <span class="sc">%&gt;%</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(issue) <span class="sc">%&gt;%</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">reframe</span>(<span class="at">joy_words_per_issue =</span> <span class="fu">n</span>()) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Joining with `by = join_by(word)`</code></pre>
</div>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>issue_tot_df <span class="ot">&lt;-</span> <span class="fu">merge</span>(issue_df, issue_joy_df, <span class="at">by=</span><span class="st">'issue'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="box type5">
<div class="sub-box">
<img src="pictures/icons/code_expl.png" alt="Icon" class="picture">
<p style="margin-left: 10px;">
</p><h5 class="anchored">
<strong>How does it work?</strong>
</h5>
<p></p>
</div>
<p>
</p><ul>
<li>
We first apply the <code>filter()</code> function to our <em>tidy_clean_content</em> data set to select data between two specific dates in order to reduce the size of our data set. We then apply the function <code>group_by()</code>. On the surface, the function does not perform any action, but from now own any further operation in the pipeline will be perfomed on groups or rows. The way rows are grouped is determined by the argument of the function, in this case <em>issue</em>. The <code>n()</code> function counts the number of rows in the DataFrame and when applied after <code>group_by(issue)</code> it counts the number of rows (words) for groups of rows sharing the same value in the <em>issue</em> column, i.e.&nbsp;the number of words in each issue. The function <code>reframe()</code> changes the format of the output DataFrame creating two columns: <em>words_per_issue</em> containing the total number of words in each issue (result of <code>n()</code>) and <em>date</em> storing the date of publication. Finally, the function <code>unique()</code> will keep only unique values of the issue;
</li>
<li>
We repeat the same operation of the previous code, but this time we join our DataFrame with <em>joy_words</em> using the function `inner_join()’. In this way, only “happy words” will be selected from <em>tidy_clean_content</em>;
</li>
<li>
We finally merge the two previously created DataFrames so to have total number of words and total number of joy words per issue in the same DataFrame.
</li>
</ul>
<p></p>
</div>
<p>The starting point is always our cleaned data <code>tidy_clean_content</code>. We first apply a filter to select news in the decade 2000-2010, then we group our data according to the issue (remember, our data has been tokenized, so at the moment each row corresponds to a single word, not to a single news or issue) and we count the number of words per issue and the number of joy words per issue. The reason for this double computation is that we would like to compare the total number of joy words with the total number of words in each issue, to obtain in this way the percentage of joy words per issue.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>issue_tot_df <span class="sc">%&gt;%</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">per_cent_joy=</span>joy_words_per_issue<span class="sc">/</span>words_per_issue<span class="sc">*</span><span class="dv">100</span>) <span class="sc">%&gt;%</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> date, <span class="at">y =</span> per_cent_joy) )<span class="sc">+</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Date"</span>, <span class="at">y =</span> <span class="st">"Joy words [%]"</span>, <span class="at">title =</span> <span class="st">"Joyfulness about EU in 2000-2010"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="text_mining_with_R_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="box type5">
<div class="sub-box">
<img src="pictures/icons/code_expl.png" alt="Icon" class="picture">
<p style="margin-left: 10px;">
</p><h5 class="anchored">
<strong>How does it work?</strong>
</h5>
<p></p>
</div>
<p>
</p><ul>
<li>
Time to plot! We first add a column to our DataFrame for plotting convenience. We use the function <code>mutate()</code> to add the column <em>per_cent_joy</em> that, indeed, stores the percent of joy words per issue;
</li>
<li>
We use <code>ggplot(aes())</code>, <code>geom_col()</code>, and <code>labs()</code> to specify x and y axis in out plot, the type of plot, and the labels for our axes, respectively.
</li>
<li>
<pre><code>&lt;/li&gt;</code></pre>
</li></ul>
<p></p>
</div>
<p>Inspecting the plot we can see that the percent of joy words never exceed the 8% and that there is a decreasing joy trend up to 2006 while values go back to a more average 4% level in 2007. 8% is a quite small value, what can we deduce from that? Text mining is a powerful technique, but like any other kind of statistics needs to be properly read according to the context. First of all, we would like to know if 8% is a particularly low value (as it seems like) or it is just the average level of joy associated with European Union news. We may even find out that the Times, by default, reports EU related news with a certain level of “coldness” so that 8% would represent a totally normal value in our sample. One of the main challenges in this case (and in general statistics) is establishing the proper level of “background joy level” or even the presence of a “joy bias” (a factor that can influence the results of an experiment in a particular direction, in our case low joy). Only determining these factors would allow us to obtain meaningfull conclusion from our “joy” levels. A deep sentimental analysis of the sample is out of the scope of this course, but you may try yourself to figure out yourself ways to make our sentiment analysis conclusions more consistent.</p>
</section>
<section id="analyzing-word-and-document-frequency-tf-idf" class="level4">
<h4 class="anchored" data-anchor-id="analyzing-word-and-document-frequency-tf-idf">Analyzing word and document frequency: tf-idf</h4>
<p>In the previous sessions we have seen how to compute and display the number of times a term appears in a text. When we divide that number by the total number of words in that text we obtain a quantity called <em>term frequency</em> (tf). The term frequency quantifies how often a word occurs in a text and at first glance it may be considered as an indicator of the importance of that term in a text. One of the goals of text mining is trying to find a way (or several ways) to extract the topic (or the sentiment or any other information) from a text, but is the most frequent term in that text a good indicator of what the text is about? Is the most frequent term the most important word in the text? Well, in most of the cases it is not and this because of for two main reasons: 1) as we already found, the most frequent terms are usually meaningless (e.g.&nbsp;stop words) and 2) the fact that a term is not used very often it does not necessarily imply that it is not important or representative for the entire text.</p>
<p>In the previous sessions we tried to deal with the first reason filtering out stop words from our text. In this session we will see how to take into account those terms that are not that frequent in a text but that can still be important to deduce its general meaning/topic/sentiment. At the same time we will define a new statistical quantity that will allow us to filter out the most frequent meaningless words without “manually” removing them from our data.</p>
<p>Let’s introduce a quantity called <strong>inverse document frequency (idf)</strong>:</p>
<p><span class="math display">\[ idf(term) = log \Bigg( {n_{documents} \over n_{documents \space containing \space term}} \Bigg) \]</span></p>
<p>As you can see from the equation, idf is a function of the term we want to focus on, this means that we can assign a unique idf to every single term in our text. Assuming that we have a sample (a set) of different documents, we start computing the document frequency in the sample, i.e.&nbsp;the ratio between the number of documents containing our selected term and the total number of documents in the sample. We then invert this quantity (that is the reason why we talk about <em>inverse</em> document frequency) and we compute the natural logarithm of this inverted quantity. Why the logarithm? Applying the logarithmic function has two advantages: 1) it makes easy to “deal” with either very small or very big numbers (it makes these numbers easier to plot, for example) and 2) when computed on a ratio of two quantities a and b, the logarithm is positive if a &gt; b and negative if b &gt; a.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="pictures/idf.jpeg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">idf</figcaption><p></p>
</figure>
</div>
<p>In our specific case, if our selected term is present in <em>all</em> the documents of our sample, then the argument of the logarithm is 1 and idf will be 0. If our selected term is present in <em>less</em> documents than the total number of documents in our sample, then idf will be positive. The less present our term is, the larger idf will be and viceversa (remember? We are dealing with <em>inverse</em> document frequency). Can idf be negative? It can’t because the number of documents containing our selected term can never be larger than the total number of documents in our sample. To summarise: idf is a positive quantity depending on a single term and it is computed over a sample of documents. The smaller the idf, the more present is our term in the sample of documents.</p>
<p>Now that we defined and got familiar with idf, it’s time to see how we use it in the context of text mining. Our goal is still to measure how important a word is in a document or in a collection (or corpus) of documents. We briefly mentioned that the term frequency (tf) alone is a misleading indicator of the importance of a word as most frequent words are often meaningless (for this reason we filtered out stop words). This time we will combine tf and idf into a single quantity called (surprisingly!) <em>tf-idf</em>. When we combine these two quantities, idf will work as a <em>weight</em> for the term frequency, <em>adjusting</em> its magnitude according to the frequency of the term in the entire corpus. It is important to keep in mind that the definition of the tf-idf quantity, and all the statistics related to it, is a <em>heuristic</em> process, i.e.&nbsp;it is a methodology that has been proved to be useful in text mining simply “by trying” and that it has not any specific theoretical motivations behind it. For our practical purpose, this simply means that any conclusion drawn from tf-idf analysis has to been taken with care.</p>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>Joining with `by = join_by(issue)`</code></pre>
</div>
</div>
<div class="box type5">
<div class="sub-box">
<img src="pictures/icons/code_expl.png" alt="Icon" class="picture">
<p style="margin-left: 10px;">
</p><h5 class="anchored">
<strong>How does it work?</strong>
</h5>
<p></p>
</div>
<p>
</p><ul>
<li>
We first tokenise our raw data using <code>unnest_tokens()</code>. We tokenise the column <em>content</em> of our DataFrame by <em>word</em>. We then use the function <code>count()</code> to count the number of words per issue, assigning the result to the DataFrame <em>issue_words</em>.
</li>
<li>
We remove any possible NA from our DataFrame applying the function <code>na.omit()</code>;
</li>
<li>
In a second R statement, we apply the function <code>group_by()</code> to the just created DataFrame <em>issue_words</em>. The function <code>group_by()</code> splits the DataFrame into groups of identical values in a specified column (in our case <em>issue</em>) so that, from now on, any other operation in the pipeline will be performed on groups of words belonging to the same issues. The function <code>summarise()</code> returns a new DataFrame (<em>total_words</em>) with one row for each group (in our case, one row per issue). Specifying as an argument <em>total = sum(n)</em>, we tell R to add a new column on the output DataFrame. This column will be named <em>total</em> and it will contain the sum of all the values of the column <em>n</em> in the <em>issue_words</em> DataFrame per group;
</li>
<li>
Finally, we join (merge) the two previously created DataFrames using the function <code>left_join()</code>. As the join is a <em>left</em> join, we mantain the structure of the first argument of the function, the <em>left</em> DataFrame <em>issue_words</em>, so one row per word and columns specifying the issue where the word was found and the number of times that word appears in that issue. After the joining operation, the output DataFrame <em>issue_total_words</em> will have an additional column named <em>total</em> containing the total number of words per issue. As same issues have same number of total words, there will be repeated values in the <em>total</em> columns, but we will deal with those later.
</li>
</ul>
<p></p>
</div>
<p>In the previous block of code we computed and stored in two DataFrames the frequency of occurrence of each word and the total number of words per issue. For computation and visualisation convenience, we then stored the word count per issue and total number of words per issue in a single DataFrame. Now it’s time to plot the term frequency per issue.</p>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
</div>
<div class="cell-output-display">
<p><img src="text_mining_with_R_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="box type5">
<div class="sub-box">
<img src="pictures/icons/code_expl.png" alt="Icon" class="picture">
<p style="margin-left: 10px;">
</p><h5 class="anchored">
<strong>How does it work?</strong>
</h5>
<p></p>
</div>
<p>
</p><ul>
<li>
We select the <em>issue_total_words</em> DataFrame and using the function <code>filter()</code> we select only those rows (words) that have a value larger than 10000 in the <em>total</em> column, i.e.&nbsp;whose belonging issues have a total number of words larger than 10000. We then apply the function <code>distinct()</code> to obtaing an output DataFrame (<em>unique_issues</em>) containing only distinct values of the column <em>issue</em>, i.e.&nbsp;one issue oer row;
</li>
<li>
Using the function <code>slice()</code>, we select the first 6 rows (1:6) of the DataFrame <em>unique_issues</em> and we store them in the DataFrame <em>first_6_unique_issues</em>;
</li>
<li>
We use the function <code>semi_join()</code> to join the DataFrames <em>issue_total_words</em> and <em>first_6_unique_issues</em> according to the column <em>issue</em>. In this way the resulting DataFrame will have the same structure of <em>issue_total_words</em> but will contain only rows with issues corresponding to the ones listed in <em>first_6_unique_issues</em>. For visualization purposes, we then apply the function <code>mutate()</code> to replace the <em>issue</em> column (containing numeric values) with a column having exactly the same name and values, but in a string (character) format. This will help the plot function to label our plots properly;
</li>
<li>
We feed the previous result to the function <code>ggplot()</code> for plotting. <code>aes()</code> is a function that stands for “aesthetics” and it is used to specify what to plot. In our case we want to plot the terms frequency, i.e.&nbsp;n/total. The color of the generated plots will vary according to the <em>issue</em> column, this is specified with <em>fill=issue</em>. We also indicate that we want to plot a histogram without legend (<code>geom_histogram(show.legend = FALSE)</code>). We also specify the boundary of the x axis with <code>xlim()</code> and that we want plots to be distributed in a grid. To do that we use the function <code>facet_wrap()</code> that will plot several plots according to the column <em>issue</em> in a grid of plots with 2 columns (ncols=2)
</li>
</ul>
<p></p>
</div>
<p>Looking at the histograms of the six longest issues in our sample, it is quite evident that the term frequency follows a very similar distribution in almost all the issues. This is because the most frequent terms in all the issues are meaningless stop words and the frequency of stop words does NOT depend on the topic or the particular issue.</p>
<p>Now that we had a look at the term frequency per issue, let’s compute the tf-idf and let’s compare these two indicators. Once again, we do not have to do that manually as the package <em>tydytext</em> provides us a specific function for this purpose:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>issue_tf_idf <span class="ot">&lt;-</span> issue_words <span class="sc">%&gt;%</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_tf_idf</span>(word, issue, n)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>issue_tf_idf <span class="sc">%&gt;%</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(tf))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 574,385 × 6
   issue word      n    tf   idf tf_idf
   &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
 1 68302 the       8 0.170     0      0
 2 52204 the      31 0.150     0      0
 3 53256 the      28 0.146     0      0
 4 53191 the      58 0.146     0      0
 5 53078 the      27 0.141     0      0
 6 57761 the      18 0.132     0      0
 7 53284 the      58 0.130     0      0
 8 53077 the      26 0.13      0      0
 9 61094 the      49 0.130     0      0
10 53175 the      76 0.130     0      0
# … with 574,375 more rows</code></pre>
</div>
</div>
<div class="box type5">
<div class="sub-box">
<img src="pictures/icons/code_expl.png" alt="Icon" class="picture">
<p style="margin-left: 10px;">
</p><h5 class="anchored">
<strong>How does it work?</strong>
</h5>
<p></p>
</div>
<p>
</p><ul>
<li>
The function <code>bind_tf_idf()</code> computes term frequency, idf, and multiples them together to obtain tf-idf. Its arguments are the name of the column containing the token (in this dase <em>word</em>), the column containing the unique identifier of the document in our sample (<em>issue</em>) and the column with the number of times the token occurs in the text (<em>n</em>). It then stores all these outputs in a DataFrame (<em>issue_tf_idf</em>) per word;
</li>
<li>
We sort the output result, the DataFrame <em>issue_tf_idf</em>, by descending values of term frequency with the function <code>arrange()</code>.
</li>
</ul>
<p></p>
</div>
<p>Looking at the first rows of the output DataFrame, it is clear that the most frequent word is “the”, a stop word. However, when we look at the corresponding tf-idf, its value is zero. This is because its idf is zero and it is an indicator that, indeed, “the” is a common word and I <em>may</em> be important, but it is <em>too much</em> common and that, perhaps, it should be excluded from our analysis.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>issue_tf_idf <span class="sc">%&gt;%</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(tf_idf))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 574,385 × 6
   issue word          n     tf   idf tf_idf
   &lt;dbl&gt; &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
 1 68732 cod          21 0.0463  7.17  0.332
 2 68277 bosnian       2 0.0435  7.17  0.312
 3 68405 code          2 0.0426  5.38  0.229
 4 68873 croatia       4 0.0317  7.17  0.228
 5 68873 rehn          4 0.0317  7.17  0.228
 6 55541 merlot        3 0.0283  7.17  0.203
 7 68578 flag          2 0.0455  4.40  0.200
 8 68890 ceausescu     2 0.0278  7.17  0.199
 9 68277 agents        2 0.0435  4.53  0.197
10 68302 wording       2 0.0426  4.61  0.196
# … with 574,375 more rows</code></pre>
</div>
</div>
<p>Arranging the tf-idf in descending order, we see in the first rows of our DataFrame rare words, but still not so rare. Rare words may indicate particularly significant events related to “European Union” as these words do not often occure in the Times news corpora. As we did for the term frequency, let’s visualise the tf-idf for the 6 longest issues in our data set:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(forcats)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>issue_tf_idf <span class="sc">%&gt;%</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">semi_join</span>(first_6_unique_issues, <span class="at">by=</span><span class="st">"issue"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(issue) <span class="sc">%&gt;%</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_max</span>(tf_idf, <span class="at">n =</span> <span class="dv">10</span>) <span class="sc">%&gt;%</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(tf_idf, <span class="fu">fct_reorder</span>(word, tf_idf), <span class="at">fill =</span> issue)) <span class="sc">+</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="at">show.legend =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>issue, <span class="at">scales=</span><span class="st">"free"</span>,<span class="at">ncol =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"tf-idf"</span>, <span class="at">y =</span> <span class="cn">NULL</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="text_mining_with_R_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Looking at the plots, five of the issues have still a word in common, while one of them (57791) stands out. This already tell us that issue 57791 could deserve particular attention.</p>
</section>
<section id="relationships-between-words" class="level4">
<h4 class="anchored" data-anchor-id="relationships-between-words">Relationships Between Words</h4>
<p>If we look at what we did so far to extract meaningful information from text, our methods look a quite over-simplification compared to the complexity of the human language: we basically counted single words computing their frequency over different samples (single text or entire corpus) and assigned them arbitrary tags to quantify which emotion they were more representative of.</p>
<p>Counting single words is a well proven text mining technique, but even more interesting is studying the <em>relation</em> between two or more words, i.e.&nbsp;which words tend to follow others immediately or tend to co-occur withing the same document.</p>
<p>In this session we will explore tidytext methods that focus on analysing and visualising the relationships between two or more words.</p>
</section>
<section id="tokenization-by-n-gram" class="level4">
<h4 class="anchored" data-anchor-id="tokenization-by-n-gram">Tokenization by n-gram</h4>
<p>We learned that the first step in text mining is tokenization, where the token can be a single character, word, a sentence, a paragraph, etc. In studying the relation between words we will start with the easiest case: relation between two words. In this case, our tokens will be groups of two consecutive words. In order to extract such groups and to render them into a DataFrame, we will use the same tidytext function that we used for tokenizing text in single words: <code>unnest_tokens()</code>. The default token for <code>unnest_tokens()</code> is single words, so that this time we need to specify that we need groups of two words. To do that, we specify the parameters <em>token</em> and <em>n</em> equal to <em>ngrams</em> and 2 respectively.</p>
<p>An <em>ngram</em> is just a contiguous sequence of items. How many items? n, so that if n=1 we have only one word, if n=2 we will have groups of two words, n=3 three words, and so on. More in general, ngrams items can be any kind of token (a single character, a word, a sentence, etc), but in this session, for simplicity, we will assume that the n-grams items are just words. If, for example, we consider the sentence “I wish I could be at Bahamas sipping a Pinacolada”, the first four word n-grams will be: - 1-gram (unigram): (“I”,“wish”,“I”,“could”,“be”,“at”,“Bahamas”,“sipping”,“a”,“Pinacolada”), the one we used in the previous paragraphs; - 2-gram (bigram): (“I wish”,“wish I”,“I could”,“could be”,“be at”,“at Bahamas”,“Bahamas sipping”,“sipping a”,“a Pinacolada”); - 3-gram (trigram): (“I wish I”,“wish I could”,“I could be”,“could be at”,“be at Bahamas”,“Bahamas sipping a”,“sipping a Pinacolada”); - 4-gram: (“I wish I could”,“wish I could be”,“I could be at”,“could be at Bahamas”,“be at Bahamas sipping”,“at Bahamas sipping a”, “Bahamas sipping a Pinacolada”).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>tidy_content_rel <span class="ot">&lt;-</span> data_df <span class="sc">%&gt;%</span> <span class="fu">unnest_tokens</span>(bigram, content, <span class="at">token=</span><span class="st">"ngrams"</span>, <span class="at">n=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="box type5">
<div class="sub-box">
<img src="pictures/icons/code_expl.png" alt="Icon" class="picture">
<p style="margin-left: 10px;">
</p><h5 class="anchored">
<strong>How does it work?</strong>
</h5>
<p></p>
</div>
<p>
</p><ul>
<li>
The previous line of code takes our raw data, <em>data_df</em>, and it injects it in the <code>unnest_tokens()</code> function. The function will look at the <em>content</em> column of the DataFrame and will split the content into tokens of 2 consecutive words stored in the column <em>bigram</em> of a new created DataFrame called <em>tidy_content_rel</em>.;
</li>
</ul>
<p></p>
</div>
<p>Let’s visualise how many times the couple of words in the <em>bigram</em> column occur in the entire corpus:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>tidy_content_rel <span class="sc">%&gt;%</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(bigram, <span class="at">sort =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(n <span class="sc">&gt;</span> <span class="dv">2000</span>) <span class="sc">%&gt;%</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">bigram =</span> <span class="fu">reorder</span>(bigram, n)) <span class="sc">%&gt;%</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(n, bigram)) <span class="sc">+</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="cn">NULL</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="text_mining_with_R_files/figure-html/unnamed-chunk-20-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The previous plot is very similar to our very first plot showing the word count in the entire corpus. The two plots are indeed identical, the only difference is that in that previous case the counted tokens were single words while now they are biagrams, i.e.&nbsp;groups of two words. Another thing we can notice is that, once again, the most frequent tokens are stop words. Let’s get rid of them:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>bigrams_separated <span class="ot">&lt;-</span> tidy_content_rel <span class="sc">%&gt;%</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">separate</span>(bigram, <span class="fu">c</span>(<span class="st">"word1"</span>, <span class="st">"word2"</span>), <span class="at">sep =</span> <span class="st">" "</span>)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>bigrams_filtered <span class="ot">&lt;-</span> bigrams_separated <span class="sc">%&gt;%</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="sc">!</span>word1 <span class="sc">%in%</span> stop_words<span class="sc">$</span>word) <span class="sc">%&gt;%</span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="sc">!</span>word2 <span class="sc">%in%</span> stop_words<span class="sc">$</span>word)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>tidy_content_rel_clean <span class="ot">&lt;-</span> bigrams_filtered <span class="sc">%&gt;%</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unite</span>(bigram, word1, word2, <span class="at">sep =</span> <span class="st">" "</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="box type5">
<div class="sub-box">
<img src="pictures/icons/code_expl.png" alt="Icon" class="picture">
<p style="margin-left: 10px;">
</p><h5 class="anchored">
<strong>How does it work?</strong>
</h5>
<p></p>
</div>
<p>
</p><ul>
<li>
Our biagram is stored in a single string (character) in the column <em>biagram</em> of our DataFrame <em>tidy_content_rel</em>. In the first instruction of the previous block of code, we first split the column <em>bigram</em> into two different columns. To do that, we use the function <code>separate()</code> specifying as arguments the column to split (<em>bigram</em>), the names of the two new columns (<em>word1</em> and <em>word2</em>), and the character that separates values in the <em>bigram</em> column (in our case, an empty space). We store the result into the DataFrame <em>bigrams_separated</em>;
</li>
<li>
Starting from <em>bigrams_separated</em>, we filter the content of the new two columns so that none of their content is a stop word. We already have a list of stop words, this is stored in the <em>word</em> column of the <em>stop_words</em> DataFrame, so what we need to do is to tell R to keep only those words that are NOT in that column. We do that with the instruction <code>!word1/2 %in% stop_words$word</code>;
</li>
<li>
Right after tokenization we had our biagram stored in a single column, so as a final step we use the function <code>unite()</code> to merge the content of the now filtered columns <em>word1</em> and <em>word2</em> back into the column <em>bigram</em>, separated by a space. We save this result into the DataFrame <em>tidy_content_rel_clean</em>.
</li>
</ul>
<p></p>
</div>
<p>As we did several times before, let’s visualise the counts of our biagram:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>tidy_content_rel_clean <span class="sc">%&gt;%</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(bigram, <span class="at">sort =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(n <span class="sc">&gt;</span> <span class="dv">500</span>) <span class="sc">%&gt;%</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">bigram =</span> <span class="fu">reorder</span>(bigram, n)) <span class="sc">%&gt;%</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(n, bigram)) <span class="sc">+</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="cn">NULL</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="text_mining_with_R_files/figure-html/unnamed-chunk-22-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>We immediately notice that the stop words are gone and that the most frequent biagrams in our corpus are “total vote” and “lab majority”.</p>
<p>Sometimes, it is useful to keep our bigrams in two distinct columns, one per word. This format could be very handy when we need to apply filtering criteria to only one of the words of the biagram. For example, we might be interested in the most common biagrams where the second word is “vote”. We already obtained this format when computing the DataFrame <em>bigrams_separated</em>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>bigrams_filtered <span class="sc">%&gt;%</span> </span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(word2 <span class="sc">==</span> <span class="st">"vote"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(issue, word1, <span class="at">sort=</span><span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 709 × 3
   issue word1      n
   &lt;dbl&gt; &lt;chr&gt;  &lt;int&gt;
 1 57897 total   1258
 2 59216 total   1222
 3 59028 total    916
 4 61556 total    602
 5 59216 rotal     15
 6 59028 rotal     10
 7 61556 6          5
 8 61556 rotal      5
 9 53127 french     4
10 61556 96         4
# … with 699 more rows</code></pre>
</div>
</div>
<p>In this case we obtain the count of all the words <em>preceding</em> the word <em>vote</em> by issue. “total” is the most frequent.</p>
<p>In the previous paragraph we mentioned that tf-idf is a function of the selected term. More in general, we can compute tf-idf for the seleced <em>token</em>, whatever it is a single character, word, biagram, n-gram, sentence, etc. To compute the tf-idf for our biagram we do not need to introduce any new tool, but we will simply use the function `bind_tf_idf()’ in a similar way as we did for single words:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>bigram_tf_idf <span class="ot">&lt;-</span> tidy_content_rel_clean <span class="sc">%&gt;%</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(issue, bigram) <span class="sc">%&gt;%</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_tf_idf</span>(bigram, issue, n) <span class="sc">%&gt;%</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(tf_idf)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>bigram_tf_idf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 328,843 × 6
   issue bigram             n        tf    idf      tf_idf
   &lt;dbl&gt; &lt;chr&gt;          &lt;int&gt;     &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt;
 1 56145 european union     1 0.0000384 0.0147 0.000000564
 2 59216 european union     3 0.0000650 0.0147 0.000000954
 3 56596 european union     2 0.0000686 0.0147 0.00000101 
 4 61556 european union     6 0.000140  0.0147 0.00000205 
 5 57897 european union     7 0.000169  0.0147 0.00000248 
 6 59028 european union     7 0.000179  0.0147 0.00000263 
 7 56120 european union     1 0.000584  0.0147 0.00000857 
 8 54346 european union     1 0.000654  0.0147 0.00000959 
 9 57791 european union     2 0.000893  0.0147 0.0000131  
10 55250 european union     1 0.000972  0.0147 0.0000143  
# … with 328,833 more rows</code></pre>
</div>
</div>
<div class="box type5">
<div class="sub-box">
<img src="pictures/icons/code_expl.png" alt="Icon" class="picture">
<p style="margin-left: 10px;">
</p><h5 class="anchored">
<strong>How does it work?</strong>
</h5>
<p></p>
</div>
<p>
</p><ul>
<li>
In order to compute idf and tf-idf, the function <code>bind_tf_idf()</code> needs our DataFrame and the name of the columns specifying tokens, document identifiers (issues), and the number of times tokens occur in each issue. Our DataFrame <em>tidy_content_rel_clean</em> does not contain this last quantity. To compute this, we apply the function <code>count()</code> specifying to count the number of identical biagrams by issue. This will return a DataFrame with three columns: <em>biagram</em>, <em>issue</em>, and <em>n</em> (the number of times that a biagram occurs in each issue). This result is used as input for <code>bind_tf_idf()</code> and the final result is arranged according to descending td_idf using <code>arrange(tf_idf)</code>.
</li>
</ul>
<p></p>
</div>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>