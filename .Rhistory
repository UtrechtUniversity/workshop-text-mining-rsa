#domain1 <- fromJSON(txt = q)
#d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
for (domain in 1:nrow(domains)) {
q <- paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]))
#domain1 <- fromJSON(txt = q)
#d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
for (domain in 1:nrow(domains)) {
q <- paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]))
#domain1 <- fromJSON(txt = q)
#d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
for (domain in 1:nrow(domains)) {
q <- paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]))
#domain1 <- fromJSON(txt = q)
#d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
for (i in 1:nrow(domains)) {
query <- paste0(url, '?KEY=', KEY, '&LOOKUP=', as.character(domains$aps.be[i])
}
for (i in 1:nrow(domains)) {
query <- paste0(url, '?KEY=', KEY, '&LOOKUP=', as.character(domains$aps.be[i])
}
for (i in 1:nrow(domains)) {
query <- paste0(url, '?KEY=', KEY, '&LOOKUP=', as.character(domains$aps.be[i])
}
for (domain in 1:nrow(domains)) {
q <- paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain])
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
q
KEY
q <- numeric(99)
q <- character()
for (domain in 1:nrow(domains)) {
q <- paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain])
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
q
q <- character()
for (domain in 1:nrow(domains)) {
q <- c(paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]))
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
q
for (domain in 1:nrow(domains)) {
q <- c(paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]))
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
q <- numeric()
for (domain in 1:nrow(domains)) {
q <- c(paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]))
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
q <- numeric()
for (domain in 1:nrow(domains)) {
q <- paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
for (domain in 1:nrow(domains)) {
q <- paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
for (domain in 1:nrow(domains)) {
q <- paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
q <- character()
for (domain in 1:nrow(domains)) {
q <- paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
for (domain in 1:nrow(domains)) {
q <- c(paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]))
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
for (domain in 1:nrow(domains)) {
q <- paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain])
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
for (domain in 1:nrow(domains)) {
query[domain] <- paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain])
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
query <- character()
for (domain in 1:nrow(domains)) {
query[domain] <- paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain])
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
quert
query
domains <- for (domain in 1:nrow(domains)) {
mutate(domains, "query" = paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]))
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
library(tidyverse)
domains <- for (domain in 1:nrow(domains)) {
mutate(domains, "query" = paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]))
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
domains <- read_csv("C:/Users/Moope001/Downloads/samplenew.csv")
for (domain in 1:nrow(domains)) {
mutate(domains, "query" = paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]))
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
for (domain in 1:nrow(domains)) {
mutate(domains, "query" = paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]))
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
for (domain in 1:nrow(domains)) {
mutate(domains, "query" = paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]))
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
View(domains)
for (domain in 1:nrow(domains)) {
mutate(domains, "query" = paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]))
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
for (domain in 1:nrow(domains)) {
domains <- mutate(domains, "query" = paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]))
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
View(domains)
for (domain in 1:nrow(domains)) {
domains[domain] <- mutate(domains, "query" = paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]))
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
for (domain in 1:nrow(domains)) {
domains <- mutate_all(domains, "query" = paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]))
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
domains <- read_csv("C:/Users/Moope001/Downloads/samplenew.csv")
for (domain in 1:nrow(domains)) {
domains <- mutate_all(domains, "query" = paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]))
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
for (domain in 1:nrow(domains)) {
domains$query <- mutate(domains, "query" = paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain]))
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
View(domains)
domains <- read_csv("C:/Users/Moope001/Downloads/samplenew.csv")
domains <- mutate(domains, "query" = paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be))
View(domains)
domains <- read_csv("C:/Users/Moope001/Downloads/samplenew.csv")
KEY <- "cec9da56-e625-4828-9d80-a12f491708b2"
url <- "https://api.builtwith.com/free1/api.json"
for (domain in 1:nrow(domains)) {
query[domain] <- paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain])
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
query <- character()
for (domain in 1:nrow(domains)) {
query[domain] <- paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain])
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
domains <- mutate(domains, "query" = paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be))
data <- list()
test1 <- GET(domain$query[1])
test1 <- GET("domain$query[1]")
test1 <- GET(query[1])
View(data)
test2 <- GET(query[2])
View(test1)
View(test2)
test1[["url"]]
test2[["url"]]
query
queries <- character()
for (domain in 1:nrow(domains)) {
queries[domain] <- paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain])
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
d1 <- GET(queries[1])
d2 <- GET(queries[2])
for (query in 1:length(queries)) {
data[query] <- GET(queries[query])
Sys.sleep(time = 10)
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
warnings()
View(data)
data[[1]]
data[[2]]
data <- list()
for (query in 1:length(queries)) {
data <- GET(queries[query])
Sys.sleep(time = 2)
# domain1 <- fromJSON(txt = q)
# d_domain1 <- as.data.frame(do.call(c, unlist(domain1, recursive = FALSE)))
}
View(data)
data[["url"]]
list
data <- list()
for (query in 1:length(queries)) {
data[[query]] <- GET(queries[query]) # does not work completely # number of items to replace is not a multiple of replacement length
Sys.sleep(time = 5)
}
View(data)
View(data)
data[[1]]
data[[3]]
data[[11]]
View(d1)
library(readr)
domains <- read_csv("C:/Users/Moope001/Downloads/samplenew.csv")
View(domains)
key <- "cec9da56-e625-4828-9d80-a12f491708b2" # update api key as necessary
url <- "https://api.builtwith.com/free1/api.json" # this is the first half of the url
queries <- character() # this is an empty character object
for (domain in 1:nrow(domains)) {
queries[domain] <- paste0(url, '?KEY=', KEY, '&LOOKUP=', domains$aps.be[domain])
}
for (domain in 1:nrow(domains)) {
queries[domain] <- paste0(url, '?KEY=', key, '&LOOKUP=', domains$aps.be[domain])
}
data <- list() # this is an empty list object
Sys.sleep(time = 2)
domains <- mutate(domains, "query" = paste0(url, '?KEY=', key, '&LOOKUP=', domains$aps.be))
for (query in 1:length(queries)) {
data[[query]] <- GET(queries[query])
Sys.sleep(time = 2)
}
View(data)
data[[1]][["url"]]
data[[10]][["url"]]
data <- list() # this is an empty list object
for (query in 1:nrow(domains)) {
data[[query]] <- GET(domain$query[query])
Sys.sleep(time = 2)
}
for (query in 1:nrow(domains)) {
data[[query]] <- GET("domain$query[query]")
Sys.sleep(time = 2)
}
install.packages("Microsoft365R")
install.packages('Microsoft365R')
library(Microsoft365R)
get_business_outlook()
outlook <- get_business_outlook()
email_body <- "## Hello!
This is an email message that was generated by the blastula package.
We can use **Markdown** formatting with the `md()` function.
Cheers,
The blastula team"
install.packages('blastula')
library(blastula)
draft_email <- compose_email(
body=md(email_body),
footer=md("sent via Microsoft365R")
)
recipients <- c(n.moopen@uu.nl, neha.moopen@gmail.com)
recipients <- c("n.moopen@uu.nl, neha.moopen@gmail.com")
email <- outlook$create_email(draft_email, subject="Hello from R", to=recipients)
email$send()
recipents
recipients
recipients <- c("n.moopen@uu.nl; neha.moopen@gmail.com")
email <- outlook$create_email(draft_email, subject="Hello from R", to=recipients)
email$send()
recipients <- c("n.moopen@uu.nl", "neha.moopen@gmail.com")
recipients
email <- outlook$create_email(draft_email, subject="Hello from R", to=recipients)
email$send()
library(zen4R)
zenodo <- ZenodoManager$new(logger = "INFO")
record <- zenodo$getRecordByDOI("10.5281/zenodo.3378733")
record <- zenodo$getRecordByDOI("10.5281/zenodo.3332807")
sessionInfo()
library(readr)
library(readxl)
Sandcollection_kim_unorganized_nonpersonal <- read_excel("C:/Users/Moope001/Downloads/Sandcollection_kim_unorganized_nonpersonal.xls")
View(Sandcollection_kim_unorganized_nonpersonal)
data <- Sandcollection_kim_unorganized_nonpersonal
summary(data)
count(data$`Herkomst land`)
library(tidyverse)
count(data$`Herkomst land`)
summarize(data$`Herkomst land`)
count(data, `Herkomst land`)
countries <- count(data, `Herkomst land`)
View(countries)
View(data)
library(usethis)
library(devtools)
install.packages("devtools")
install_github("holtzy/epuRate")
library(devtools)
install_github("holtzy/epuRate")
library(epuRate)
getwd()
install.packages("openalexR")
library(openalexR)
library(dplyr)
test <- oa_fetch(
entity = "works",
title.search = c("bibliometric analysis", "science mapping"),
cited_by_count = ">50",
from_publication_date = "2020-01-01",
to_publication_date = "2021-12-31",
sort = "cited_by_count:desc",
count_only = FALSE)
View(test)
test <- oa_fetch(
entity = "works",
title.search = c("bibliometric analysis", "science mapping"),
cited_by_count = ">50",
from_publication_date = "2020-01-01",
to_publication_date = "2021-12-31",
sort = "cited_by_count:desc",
count_only = FALSE) %>%
show_works()
View(test)
test <- oa_fetch(
entity = "works",
title.search = c("bibliometric analysis", "science mapping"),
cited_by_count = ">50",
from_publication_date = "2020-01-01",
to_publication_date = "2021-12-31",
sort = "cited_by_count:desc",
count_only = FALSE)
test2 <- show_works(test)
View(test2)
View(test)
test <- oa_fetch(
entity = "works",
title.search = c("bibliometric analysis", "science mapping"),
cited_by_count = ">50",
from_publication_date = "2020-01-01",
to_publication_date = "2021-12-31",
sort = "cited_by_count:desc",
count_only = FALSE)
View(test)
test <- oa_fetch(
entity = "works",
title.search = c("social media", "adolescents"),
cited_by_count = ">50",
from_publication_date = "2020-01-01",
to_publication_date = "2021-12-31",
sort = "cited_by_count:desc",
count_only = FALSE)
View(test)
install.packages("openalexR")
library(openalexR)
library(dplyr)
works_search <- oa_fetch(
entity = "works",
title.search = c("bibliometric analysis", "science mapping"),
cited_by_count = ">50",
from_publication_date = "2020-01-01",
to_publication_date = "2021-12-31",
sort = "cited_by_count:desc",
verbose = TRUE
)
View(works_search)
show_works(works_search)
works_search_clean <- show_works(works_search)
View(works_search_clean)
works_search <- oa_fetch(
entity = "works",
title.search = c("bibliometric analysis", "science mapping"),
cited_by_count = ">50",
from_publication_date = "2020-01-01",
to_publication_date = "2021-12-31",
sort = "cited_by_count:desc",
verbose = TRUE
)
View(works_search)
works_search_clean <- show_works(works_search)
View(works_search_clean)
works_search <- oa_fetch(
entity = "works",
title.search = c("risk behavior", "adolescents"),
cited_by_count = ">50",
from_publication_date = "2015-01-01",
to_publication_date = "2021-12-31",
sort = "cited_by_count:desc",
verbose = TRUE
)
works_search_clean <- show_works(works_search)
View(works_search_clean)
View(works_search)
View(works_search_clean)
View(works_search)
works_from_dois <- oa_fetch(
doi = c("https://doi.org/10.1007/s10964-020-01201-5", "https://doi.org/10.1111/jora.12651", "https://doi.org/10.1080/08927936.2021.1938405"),
entity = "works",
verbose = TRUE
)
View(works_from_dois)
View(works_from_dois)
works_from_dois <- oa_fetch(
doi = c("https://doi.org/10.1007/s10964-020-01201-5", "https://doi.org/10.1111/jora.12651", "https://doi.org/10.1080/08927936.2021.1938405", "10.1016/j.cpr.2014.06.006"),
entity = "works",
verbose = TRUE
)
View(works_from_dois)
library(readr)
library(readxl)
papers_to_check <- readxl::read_excel("C:\Users\Moope001\Downloads\papers-to-check.xlsx")
papers_to_check <- readxl::read_excel("C:/Users/Moope001/Downloads/papers-to-check.xlsx")
View(papers_to_check)
?read_excel
papers_to_check <- readxl::read_excel("C:/Users/Moope001/Downloads/papers-to-check.xlsx", col_names = FALSE)
View(papers_to_check)
papers <- c(papers_to_check$...1)
title.search = c(papers_to_check$...1)
works_search <- oa_fetch(
entity = "works",
title.search = c(papers_to_check$...1))
works_search <- oa_fetch(
entity = "works",
title.search = c(papers_to_check$...1))
View(papers_to_check)
works_search <- oa_fetch(
entity = "works",
title.search = c("The relationship between juvenile psychopathic traits, delinquency And (violent) recidivism: A Meta-Analysis"))
View(papers_to_check)
library(stringr)
papers_to_check$...1 <- str_extract(papers_to_check$...1, "(?=10)(.*?)(?<=\\s)")
View(papers_to_check)
papers_to_check <- readxl::read_excel("C:/Users/Moope001/Downloads/papers-to-check.xlsx", col_names = FALSE)
papers <- str_extract(papers_to_check$...1, "(?=10)(.*?)(?<=\\s)")
papesr
papers
View(papers_to_check)
papers <- str_extract(papers_to_check$...1, "(?=10)")
papesr
papers
View(papers_to_check)
papers <- str_extract(papers_to_check$...1, "10.\\d{4,9}/[-._;()/:a-z0-9A-Z]+"")
papers <- c(papers_to_check$...1)
papers <-
works_from_dois <- oa_fetch(
doi = papers,
entity = "works",
papers <- str_extract(papers_to_check$...1, "10.\\d{4,9}/[-._;()/:a-z0-9A-Z]+"")
papers <- str_extract(papers_to_check$...1, "10.\\d{4,9}/[-._;()/:a-z0-9A-Z]+")
papers <- str_extract(papers_to_check$...1, "10.\\d{4,9}/[-._;()/:a-z0-9A-Z]+")
papesr
papers
works_from_dois <- oa_fetch(
doi = papers,
entity = "works",
verbose = TRUE)
View(works_from_dois)
papers_tidy <- show_works(works_from_dois)
View(papers_tidy)
wrks <- unlist(works_from_dois)
wrks
wrks <- data.frame(works_from_dois)
View(wrks)
View(papers_tidy)
works_to_check <- readxl::read_excel("C:/Users/Moope001/Downloads/papers-to-check.xlsx", col_names = FALSE)
works_doi <- str_extract(works_to_check$...1, "10.\\d{4,9}/[-._;()/:a-z0-9A-Z]+")
works <- oa_fetch(
doi = works_doi,
entity = "works",
verbose = TRUE)
works_tidy <- show_works(works)
View(works_tidy)
works_doi
View(works)
colnames(works)
works_tidy <- select(works, c("display_name", "so", "url", "is_oa", "publication_year", "doi"))
View(works_tidy)
library(writexl)
works_tidy <- select(works, c("display_name", "so", "url", "is_oa", "doi"))
writexl::write_xlsx(works_tidy, "~/Downloads/works_tidy.xlsx")
writexl::write_xlsx(works_tidy, "works_tidy.xlsx")
.Renviron
usethis::edit_r_environ()
setwd("~/programming/workshop-text-mining-rsa")
library(xaringanExtra)
library(vembedr)
xaringanExtra::embed_xaringan(url = "https://utrechtuniversity.github.io/workshop-introduction-to-R-and-data/slides/slides_introduction.html#18", ratio = "4:3")
xaringanExtra::embed_xaringan(url = "https://utrechtuniversity.github.io/workshop-introduction-to-R-and-data/slides/slides_introduction.html#18", ratio = "4:3")
xaringanExtra::embed_xaringan(url = "https://utrechtuniversity.github.io/workshop-introduction-to-R-and-data/slides/slides_introduction.html#18", ratio = "4:3")
vembedr::embed_url("https://www.youtube.com/watch?v=S8zTmEvpYYk")
xaringanExtra::embed_xaringan(url = "https://utrechtuniversity.github.io/workshop-introduction-to-R-and-data/slides/slides_introduction.html#27", ratio = "4:3")
library(dplyr)
install.packages("dplyr")
